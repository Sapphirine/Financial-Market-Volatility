{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf210
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww17020\viewh14400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\f0\fs24 \cf0 Final Report - John Terzis \
Note: This is not meant to be entire report but rather should be inserted into final report\
\
\

\fs28 Introduction\
\
Related Works\
\
System Overview\
\
\
Algorithm\
\

\fs24 Preprocessor:\
The pre-processing of the raw data is divided programmatically into several python modules\
and associated bash scripts. The first module employed on the data residing in a specific directory\
as text files is joinfeatures.py. This routine walks through the raw data directory merging predesignated input data with each stock symbol\'92s data on the timestamp index and stores\
the resultant merged datasets as csv files.\
\
The map-reduce modules in mapper.py and reducer.py take over the pre-processing from here\
dividing the merged data files into key-value pairs where each key is of the form SYMBOL-STARTDATE-ENDDATE and each value is the associated subset of rows from the data file whose timestamp is within the interval [STARTDATE, ENDDATE] and whose filename equals SYMBOL. \
\
The reducer in reducer.py takes in values for each key that correspond to closing price data for the symbol and the input data that was merged with the symbol in the prior step by joinfeatures.py. Then for every row (1 minute closing price observation),\
the algorithm populates previous (in time) and future timestamps with closing prices and calculates the absolute value of the\
return for these \'93displaced\'94 closing prices versus the current timestamp. A resultant row from the reduce step looks like\
KEY | CLOSING_PRICE | 60-DAY FUTURE VOLATILITY | 60-DAY PAST VOLATILITY etc .\
vol_mapred.sh runs the mapper and reducer using hadoop streaming jar and parameters set in mapred-site.xml to tweak\
the memory upwards that java has access to in the heap given the high memory usage in the reduce step.\
\

\fs28 \
\
Software Package Description\

\fs24 \
The pre-processor consists of python modules packaged in the MapReduce folder. The eventual goal of the pre-processing\
step is to build a feature matrix from the raw price data that can be used for regression to form a model that can predict\
volatility and a separate feature matrix that can be used to perform time series clustering on the intra-day price data between symbols. \
\
The initial data started out as text files for each symbol (stocks,futures,forex,rtfs) with open high low close price data at the minute granularity timestamp as shown below.\
\
\
\
Below is an example of a row from the feature matrix of symbol PEP . This subset of columns can be used in a regression model to predict future 90 day volatility for PEP.\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural
\cf0 {{\NeXTGraphic Screen Shot 2014-12-21 at 1.45.40 PM.png \width13680 \height10720
}¬}\
Below is an example of a stock PEP\'92s transformed clustering matrix. Again the rows correspond to half hour intervals within a trading day and the columns\
are 30 min return observations across the 20 year history of raw price data we have on this stock.\
\
\
{{\NeXTGraphic Screen Shot 2014-12-21 at 1.48.12 PM.png \width13680 \height10720
}¬}\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural
\cf0 The script Joinfeatures.py is meant to run as a python script on command line as \'93python joinfeatures.py\'94 . Once resultant merged data is available, map reduce is ready to run using the helper script , vol_mapreduce.sh. You should see the hadoop streaming reporting incremental results of map-reduce as below.\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural
\cf0 {{\NeXTGraphic Screen Shot 2014-12-21 at 1.56.44 PM.png \width14060 \height8200
}¬}\
The SparkRegressor Package also included consists of a module, svm.py, that runs regularized ridge regression using Stochastic Gradient Descent\
over pyspark and hadoop. To run this script, set the parameters such as the input file URI and output file URI\'92s in constants.py within the package\
and run using the command \'93/bin/pyspark svm.py\'94 . 
\fs28 \
\
Experimental Results\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural
\cf0 \

\fs24 Ridge Regression was run on AIG stock quotes between 2008 and 2001 from the transformed feature matrix generated by map reduce\
to produce a functional regressor of the form f(x) = y where y = AIG 7 Day Future Volatility and x was a vector of the following form:\
[AIG previous 60 minute volatility, AIG previous 3 day vol, AIG previous 7 day vol, SP500 previous 20 day vol, VIX previous 20 day vol,\
ES previous 1 day vol, ES previous 7 Day vol, VIX previous 1 day vol, VIX previous 7 day vol, EURUSD previous 7 day vol, XLE previous\
7 day vol]\
\
The results shown below were obtained using 2 fold cross validation. The R^2 error metric was calculated in the test set which was\
not used to train the model. As initial results, this framework and model seems to have predictive power, which lends to our theory that\
volatility is predictable at specific time intervals (as oppose to mere price behavior). Below is the resultant betas, slope , and R^2 for Ridge\
Regression run on AIG.
\fs28 \
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural

\fs24 \cf0 {{\NeXTGraphic rr_results2.png \width7320 \height5600
}¬}
\fs28 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural
\cf0 \
\
Conclusion\
\
\
\
\
References\

\fs24 \
1.  H. Yang, L. Chan, I. King, \'93Support Vector Machine Regression for Volatile Stock Market Prediction\'94 Intelligent Data Engineering and Automated Learning - IDEAL 2002\
\
}